services:
  nemollm-inference:
    container_name: nemollm-inference-microservice
    image: nvcr.io/nim/meta/llama-3.2-3b-instruct:1.8.4
    volumes:
    - /home/nvidia/.cache/model-cache:/opt/nim/.cache
    user: ""
    ports:
    - "8000:8000"
    expose:
    - "8000"
    environment:
      NGC_API_KEY: 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
      NIM_KVCACHE_PERCENT: 0.4
    shm_size: 16gb
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              # device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://localhost:8000/v1/health/ready')"]
      interval: 10s
      timeout: 20s
      retries: 100
    profiles: ["local-nim", "nemo-retriever"]

  nemollm-embedding:
    container_name: nemo-retriever-embedding-microservice
    image: nvcr.io/nim/nvidia/nv-embedqa-e5-v5:1.6
    volumes:
    - /home/nvidia/.cache/model-cache:/opt/nim/.cache
    ports:
    - "9080:8000"
    expose:
    - "8000"
    environment:
      NGC_API_KEY: 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
    user: ""
    shm_size: 16GB
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v1/health/ready"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 10m
    profiles: ["local-nim", "nemo-retriever"]

  ranking-ms:
    container_name: nemo-retriever-ranking-microservice
    image: nvcr.io/nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:1.5.0
    volumes:
    - /home/nvidia/.cache/model-cache:/opt/nim/.cache
    ports:
    - "1976:8000"
    expose:
    - "8000"

